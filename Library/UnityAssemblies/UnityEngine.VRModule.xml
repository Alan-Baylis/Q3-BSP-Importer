<?xml version="1.0" encoding="utf-8"?>
<doc>
  <!-- Generated by uIntelliSense 1.8.0.0 -->
  <assembly>
    <name>UnityEngine.VRModule</name>
  </assembly>
  <members>
    <member name="T:UnityEngine.XR.WSA.Input.GestureErrorEventArgs">
      <summary>
        <para>Contains fields that are relevant during an error event.</para>
        <para>To receive this information, you should register with GestureError.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.GestureRecognizer">
      <summary>
        <para>Manager class with API for recognizing user gestures.</para>
        <para>GestureRecognizer performs only the minimal disambiguation between the set of gestures that you request. For example, if you request just Tap, the user may hold their finger down as long as they like and a Tap will still occur when the user releases their finger. GestureRecognizers will only receive events after StartCapturingGestures is called. StopCapturingGestures can be called again to stop events. This allows for GestureRecognizer to be activated and deactivated on demand such as when a users gaze moves over and away from an object.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.HoldCanceledEventArgs">
      <summary>
        <para>Contains fields that are relevant when a user cancels a hold gesture.</para>
        <para>Users should register with HoldCanceled.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.HoldCompletedEventArgs">
      <summary>
        <para>Contains fields that are relevant when a hold gesture completes.</para>
        <para>Users should register with HoldCompleted.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.HoldStartedEventArgs">
      <summary>
        <para>Contains fields that are relevant when a hold gesture starts.</para>
        <para>Users should register with HoldStarted.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.InteractionManager">
      <summary>Provides access to user input from hands, controllers, and system voice commands.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.InteractionSource">
      <summary>
        <para>Represents one detected instance of an interaction source (hand, controller, or user's voice) that can cause interactions and gestures.</para>
        <para>This object should be the same between events and polls from <see cref="UnityEngine.XR.WSA.Input.InteractionManager"></see> as well as in gesture events from <see cref="UnityEngine.XR.WSA.Input.GestureRecognizer"></see> for the same interaction source.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.InteractionSourceDetectedEventArgs">
      <summary>
        <para>Contains fields that are relevent when an interaction source is detected.</para>
        <para>To receive this information, subscribe to InteractionSourceDetected.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.InteractionSourceLocation">
      <summary>Represents the position and velocity of a hand or controller - this has been deprecated. Use <see cref="UnityEngine.XR.WSA.Input.InteractionSourcePose"></see> instead.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.InteractionSourceLostEventArgs">
      <summary>
        <para>Contains fields that are relevent when an interaction source is lost.</para>
        <para>To receive this information, subscribe to InteractionSourceLost.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.InteractionSourcePose">
      <summary>Pose data of the interaction source at the time of either the gesture or interaction.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.InteractionSourcePressedEventArgs">
      <summary>
        <para>Contains fields that are relevent when an interaction source enters the pressed state for one of its buttons.</para>
        <para>To receive this information, subscribe to InteractionSourcePressed.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.InteractionSourceProperties">
      <summary>Represents the set of properties available to explore the current state of a hand or controller.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.InteractionSourceReleasedEventArgs">
      <summary>
        <para>Contains fields that are relevent when an interaction source exits the pressed state for one of its buttons.</para>
        <para>To receive this information, subscribe to InteractionSourceReleased.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.InteractionSourceState">
      <summary>Represents a snapshot of the state of a spatial interaction source (hand, voice or controller) at a given time.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.InteractionSourceUpdatedEventArgs">
      <summary>
        <para>Contains fields that are relevent when an interaction source updates.</para>
        <para>To receive this information, subscribe to InteractionSourceUpdated.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.ManipulationCanceledEventArgs">
      <summary>
        <para>Contains fields that are relevant when a manipulation gesture is canceled.</para>
        <para>To receive this information, you should register with ManipulationCanceled.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.ManipulationCompletedEventArgs">
      <summary>
        <para>Contains fields that are relevant when a manipulation gesture completes.</para>
        <para>To receive this information, you should register with ManipulationCompleted.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.ManipulationStartedEventArgs">
      <summary>
        <para>Contains fields relevant when a manipulation gesture starts.</para>
        <para>To receive this information, you should register with ManipulationStarted.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.ManipulationUpdatedEventArgs">
      <summary>
        <para>Contains fields that are relevant when a manipulation gesture gets updated.</para>
        <para>To receive this information, you should register with ManipulationUpdated.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.NavigationCanceledEventArgs">
      <summary>
        <para>Contains fields that are relevant when a navigation gesture is canceled.</para>
        <para>To receive this information, you should register with NavigationCanceled.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.NavigationCompletedEventArgs">
      <summary>
        <para>Contains fields that are relevant when a navigation gesture completes.</para>
        <para>To receive this information, you should register with NavigationCompleted.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.NavigationStartedEventArgs">
      <summary>
        <para>Contains fields that are relevant when a navigation gesture starts.</para>
        <para>To receive this information, you should register with NavigationStarted.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.NavigationUpdatedEventArgs">
      <summary>
        <para>Contains fields that are relevant when a navigation gesture updates.</para>
        <para>To receive this information, you should register with NavigationUpdated.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.RecognitionEndedEventArgs">
      <summary>
        <para>Contains fields that are relevant when recognition of a gesture event ends.</para>
        <para>To receive this information, you should register with RecognitionEnded.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.RecognitionStartedEventArgs">
      <summary>
        <para>Contains fields that are relevant when recognition of a gesture event begins.</para>
        <para>To receive this information, you should register with RecognitionStarted.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.TappedEventArgs">
      <summary>
        <para>Contains fields that are relevant when a tap gesture occurs.</para>
        <para>To receive this information, you should register with Tapped.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.GestureSettings">
      <summary>
        <para>This enumeration represents the set of gestures that may be recognized by <see cref="UnityEngine.XR.WSA.Input.GestureRecognizer"></see>.</para>
        <para>
          <see cref="UnityEngine.XR.WSA.Input.GestureRecognizer">
          </see> performs only the minimal disambiguation between the set of gestures that you request. For example, if you request just Tap, the user may hold their finger down as long as they like and a Tap will still occur when the user releases their finger.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.InteractionSourceHandedness">
      <summary>Denotes which hand was used as the input source.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.InteractionSourceKind">
      <summary>
        <para>Specifies the kind of an interaction source.</para>
        <para>This only enumerates sources of interactions, such as hand gestures and voice commands.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.InteractionSourceNode">
      <summary>Specifies which part of the controller to query pose information for.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.InteractionSourcePositionAccuracy">
      <summary>Denotes the accuracy of tracking on the interaction source.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Input.InteractionSourcePressType">
      <summary>The type of button or controller feature pressed, if any.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Persistence.WorldAnchorStore">
      <summary>The storage object for persisted WorldAnchors.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Sharing.WorldAnchorTransferBatch">
      <summary>A batch of WorldAnchors which can be exported and imported between apps.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.Sharing.SerializationCompletionReason">
      <summary>This enum represents the result of a WorldAnchorTransferBatch operation.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.WebCam.CameraParameters">
      <summary>When calling <see cref="UnityEngine.XR.WSA.WebCam.PhotoCapture.StartPhotoModeAsync"></see>, you must pass in a CameraParameters object that contains the various settings that the web camera will use.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.WebCam.PhotoCapture">
      <summary>
        <para>Captures a photo from the web camera and stores it in memory or on disk.</para>
        <para>Demonstrates how to take a photo using the PhotoCapture functionality and display it on a Unity GameObject.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.WebCam.PhotoCapture.PhotoCaptureResult">
      <summary>A data container that contains the result information of a photo capture operation.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.WebCam.PhotoCapture.CaptureResultType">
      <summary>
        <para>Contains the result of the capture request.</para>
        <para>More generic error types may be added at a later time.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.WebCam.PhotoCaptureFrame">
      <summary>
        <para>Contains information captured from the web camera.</para>
        <para>Information captured can include the image has well as spatial data.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.WebCam.VideoCapture">
      <summary>
        <para>Records a video from the web camera directly to disk.</para>
        <para>The final video recording will be stored on the file system in the MP4 format. The example below records a 5 second video to the file system.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.WebCam.VideoCapture.VideoCaptureResult">
      <summary>A data container that contains the result information of a video recording operation.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.WebCam.VideoCapture.AudioState">
      <summary>Specifies what audio sources should be recorded while recording the video.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.WebCam.VideoCapture.CaptureResultType">
      <summary>Contains the result of the capture request.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.WebCam.WebCam">
      <summary>Contains general information about the current state of the web camera.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.WebCam.CapturePixelFormat">
      <summary>The encoded image or video pixel format to use for PhotoCapture and VideoCapture.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.WebCam.PhotoCaptureFileOutputFormat">
      <summary>
        <para>Image Encoding Format.</para>
        <para>The image encoding format that should be used when saving the texture to disk.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.WebCam.WebCamMode">
      <summary>
        <para>Describes the active mode of the Web Camera resource.</para>
        <para>The Web Camera resource can only be in one mode at any given time.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.HolographicSettings">
      <summary>The Holographic Settings contain functions which effect the performance and presentation of Holograms on Windows Holographic platforms.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.SurfaceData">
      <summary>SurfaceData is a container struct used for requesting baked spatial mapping data and receiving that data once baked.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.SurfaceId">
      <summary>SurfaceId is a structure wrapping the unique ID used to denote Surfaces. SurfaceIds are provided through the onSurfaceChanged callback in Update and returned after a RequestMeshAsync call has completed. SurfaceIds are guaranteed to be unique though Surfaces are sometimes replaced with a new Surface in the same location with a different ID.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.SurfaceObserver">
      <summary>
        <para>SurfaceObserver is the main API portal for spatial mapping functionality in Unity.</para>
        <para>Users should create an SurfaceObserver, call Update to generate SurfaceChanged events, call GetMeshAsync for those surfaces that are interesting, and call Dispose when finished with the object.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.WorldAnchor">
      <summary>
        <para>The WorldAnchor component allows a GameObject's position to be locked in physical space.</para>
        <para>For example, a cube arranged on top of a physical desk with a WorldAnchor applied will remain fixed even as an observer walks around the room. This overrides all manipulation of the GameObject's position and orientation. To move the GameObject, first remove the WorldAnchor and manipulate the Transform normally. While it is generally recommended to use Destroy instead of DestroyImmediate, it's best to call DestroyImmediate on WorldAnchor objects. Doing so will let you manipulate the Transform of the GameObject including adding a new WorldAnchor.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.WorldManager">
      <summary>This class represents the state of the real world tracking system.</summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.PositionalLocatorState">
      <summary>
        <para>Indicates the lifecycle state of the device's spatial location system.</para>
        <para>This is the tracking state for the device. It lets your application know whether position and orientation in the user's surroundings are available from the device.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.WSA.SurfaceChange">
      <summary>Enumeration of the different types of SurfaceChange events.</summary>
    </member>
    <member name="T:UnityEngine.XR.InputTracking">
      <summary>A collection of methods and properties for interacting with the XR tracking system.</summary>
    </member>
    <member name="T:UnityEngine.XR.XRDevice">
      <summary>Contains all functionality related to a XR device.</summary>
    </member>
    <member name="T:UnityEngine.XR.XRSettings">
      <summary>Global XR related settings.</summary>
    </member>
    <member name="T:UnityEngine.XR.XRStats">
      <summary>
        <para>Timing and other statistics from the XR subsystem.</para>
        <para>Some XR SDKs provide access to additional timing and other statistics. These can be used by games and applications for profiling and dynamic performance adjustments. For example, modifying <see cref="UnityEngine.XR.XRSettings.eyeTextureResolutionScale"></see> or <see cref="UnityEngine.XR.XRSettings.renderViewportScale"></see> during runtime can improve performance. This class exposes a set of information that can be optionally reported by SDKs. Make sure to use the return values of any methods to know whether the data is being reported by the SDK or not.</para>
      </summary>
    </member>
    <member name="T:UnityEngine.XR.TrackingSpaceType">
      <summary>Represents the size of physical space available for XR.</summary>
    </member>
    <member name="T:UnityEngine.XR.UserPresenceState">
      <summary>Represents the current user presence state detected by the device.</summary>
    </member>
    <member name="T:UnityEngine.XR.XRNode">
      <summary>Enumeration of tracked XR nodes which can be updated by XR input.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.HoldCompletedEventArgs.headPose">
      <summary>Head pose of the user at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.HoldCompletedEventArgs.source">
      <summary>
        <para>The <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> (hand, controller, or user's voice) that completed the hold gesture.</para>
        <para>Interactions captured via <see cref="UnityEngine.XR.WSA.Input.InteractionManager"></see>, as well as other gesture events, should have a matching <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> for the same hand, controller, or user's voice.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.HoldCompletedEventArgs.sourcePose">
      <summary>Pose data of the interaction source at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.HoldStartedEventArgs.headPose">
      <summary>Head pose of the user at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.HoldStartedEventArgs.source">
      <summary>
        <para>The <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> (hand, controller, or user's voice) that started the hold gesture.</para>
        <para>Interactions captured via <see cref="UnityEngine.XR.WSA.Input.InteractionManager"></see>, as well as other gesture events, should have a matching <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> for the same hand, controller, or user's voice.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.HoldStartedEventArgs.sourcePose">
      <summary>Pose data of the interaction source at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.ManipulationUpdatedEventArgs.cumulativeDelta">
      <summary>Total distance moved since the beginning of the manipulation gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.ManipulationUpdatedEventArgs.headPose">
      <summary>Head pose of the user at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.ManipulationUpdatedEventArgs.source">
      <summary>
        <para>The <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> (hand, controller, or user's voice) being used for the manipulation gesture.</para>
        <para>Interactions captured via <see cref="UnityEngine.XR.WSA.Input.InteractionManager"></see>, as well as other gesture events, should have a matching <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> for the same hand, controller, or user's voice.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.ManipulationUpdatedEventArgs.sourcePose">
      <summary>Pose data of the interaction source at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceReleasedEventArgs.pressType">
      <summary>Denotes the type of button that was just released.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceReleasedEventArgs.state">
      <summary>The current state of the reported interaction source that just had one of its buttons exit the pressed state.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceState.anyPressed">
      <summary>
        <para>True if the source is in the pressed state.</para>
        <para>This can be because the hand has a finger pressed or the controller has any button pressed.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceState.grasped">
      <summary>
        <para>Whether the controller is grasped.</para>
        <para>The grasp buttons are generally found on the sides of the controller.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceState.headPose">
      <summary>Head pose of the user at the time of the interaction.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceState.menuPressed">
      <summary>Whether or not the menu button is pressed.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceState.properties">
      <summary>Additional properties to explore the state of the interaction source.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceState.selectPressed">
      <summary>Depending on the InteractionSourceType of the interaction source, this returning true could represent a number of equivalent things: main button on a clicker, air-tap on a hand, and the trigger on a motion controller. For hands, a select-press represents the user's index finger in the down position. For motion controllers, a select-press represents the controller's index-finger trigger (or primary face button, if no trigger) being fully pressed. Note that a voice command of "Select" causes an instant press and release, so you cannot poll for a voice press using this property - instead, you must use <see cref="UnityEngine.XR.WSA.Input.GestureRecognizer"></see> and subscribe to the Tapped event, or subscribe to the InteractionSourcePressed event from <see cref="UnityEngine.XR.WSA.Input.InteractionManager"></see>.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceState.selectPressedAmount">
      <summary>
        <para>Normalized amount ([0, 1]) representing how much select is pressed.</para>
        <para>Depending on the InteractionSourceType of the interaction source, this returning a non-zero could represent a number of equivalent things: main button on a blicker, air-tap on a hand, and the trigger on a motion controller.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceState.source">
      <summary>The interaction source that this state describes.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceState.sourcePose">
      <summary>Pose data of the interaction source at the time of the interaction.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceState.thumbstickPosition">
      <summary>
        <para>Normalized coordinates for the position of a thumbstick.</para>
        <para>(0, 0) is the resting position of the thumbstick. Each component lies in the range [-1, 1]. -1 maps to left on the x-axis and down on the y-axis; 1 maps to right on the x-axis and up on the y-axis.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceState.thumbstickPressed">
      <summary>Whether or not the thumbstick is pressed.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceState.touchpadPosition">
      <summary>
        <para>Normalized coordinates for the position of a touchpad interaction.</para>
        <para>(0, 0) is the resting position of the touchpad, or if the touchpad isn't touched at the time. Each component lies in the range [-1, 1]. -1 maps to left on the x-axis and down on the y-axis; 1 maps to right on the x-axis and up on the y-axis.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceState.touchpadPressed">
      <summary>Whether or not the touchpad is pressed, as if a button.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceState.touchpadTouched">
      <summary>Whether or not the touchpad is touched.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceUpdatedEventArgs.state">
      <summary>The current state of the reported interaction source that just updated.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.ManipulationCanceledEventArgs.headPose">
      <summary>Head pose of the user at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionManager.numSourceStates">
      <summary>
        <para>(Read Only) The number of <see cref="UnityEngine.XR.WSA.Input.InteractionSourceState"></see> snapshots available for reading with <see cref="UnityEngine.XR.WSA.Input.InteractionManager.GetCurrentReading"></see>.</para>
        <para>This can be used to reserve storage in an array for retrieving interaction source states without triggering an allocation.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.ManipulationCanceledEventArgs.source">
      <summary>
        <para>The <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> (hand, controller, or user's voice) that canceled the manipulation gesture.</para>
        <para>Interactions captured via <see cref="UnityEngine.XR.WSA.Input.InteractionManager"></see>, as well as other gesture events, should have a matching <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> for the same hand, controller, or user's voice.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.ManipulationCanceledEventArgs.sourcePose">
      <summary>Pose data of the interaction source at the time of the gesture.</summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.Input.InteractionManager.GetCurrentReading">
      <summary>Get the current SourceState.</summary>
      <returns>An array of <see cref="UnityEngine.XR.WSA.Input.InteractionSourceState"></see> snapshots.</returns>
    </member>
    <member name="M:UnityEngine.XR.WSA.Input.InteractionManager.GetCurrentReading(UnityEngine.XR.WSA.Input.InteractionSourceState[])">
      <summary>Allows retrieving the current source states without allocating an array. The number of retrieved source states will be returned, up to a maximum of the size of the array.</summary>
      <param name="sourceStates">An array for storing <see cref="UnityEngine.XR.WSA.Input.InteractionSourceState"></see> snapshots.</param>
      <returns>The number of snapshots stored in the array, up to the size of the array.</returns>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.ManipulationCompletedEventArgs.cumulativeDelta">
      <summary>Total distance moved since the beginning of the manipulation gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.ManipulationCompletedEventArgs.headPose">
      <summary>Head pose of the user at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.ManipulationCompletedEventArgs.source">
      <summary>
        <para>The <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> (hand, controller, or user's voice) that completed the manipulation gesture.</para>
        <para>Interactions captured via <see cref="UnityEngine.XR.WSA.Input.InteractionManager"></see>, as well as other gesture events, should have a matching <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> for the same hand, controller, or user's voice.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.ManipulationCompletedEventArgs.sourcePose">
      <summary>Pose data of the interaction source at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.ManipulationStartedEventArgs.headPose">
      <summary>Head pose of the user at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.ManipulationStartedEventArgs.source">
      <summary>
        <para>The <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> (hand, controller, or user's voice) that started the manipulation gesture.</para>
        <para>Interactions captured via <see cref="UnityEngine.XR.WSA.Input.InteractionManager"></see>, as well as other gesture events, should have a matching <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> for the same hand, controller, or user's voice.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.ManipulationStartedEventArgs.sourcePose">
      <summary>Pose data of the interaction source at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourcePose.positionAccuracy">
      <summary>The position-tracking accuracy of the interaction source.</summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.Input.InteractionSourcePose.TryGetAngularVelocity(UnityEngine.Vector3@)">
      <summary>Attempts to retrieve a Vector3 representing the current angular velocity of the tracked node.</summary>
      <param name="angularVelocity">If the function returns true, this will be filled out with the angular velocity of the interaction source. If the function returns false, the value filled out should not be used.</param>
      <returns>True if the angular velocity was set in the output parameter. False if the angular velocity is not available due to limitations of the underlying platform or if the node is not presently tracked.</returns>
    </member>
    <member name="M:UnityEngine.XR.WSA.Input.InteractionSourcePose.TryGetForward(UnityEngine.Vector3@,UnityEngine.XR.WSA.Input.InteractionSourceNode)">
      <summary>Gets the forward vector of the interaction source, assuming rotation is valid.</summary>
      <param name="forward">The forward vector of the interaction source, if the function returns true.</param>
      <param name="node">Specifies which part of the controller to query for its forward vector.</param>
      <returns>This method returns true when the rotation is valid and the Vector3 passed in was filled out correctly, and false if otherwise.</returns>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.HoldCanceledEventArgs.headPose">
      <summary>Head pose of the user at the time of the gesture.</summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.Input.InteractionSourcePose.TryGetPosition(UnityEngine.Vector3@,UnityEngine.XR.WSA.Input.InteractionSourceNode)">
      <summary>Gets the position of the interaction source, assuming the backing data is valid.</summary>
      <param name="position">The position of the interaction source, is the function returns true.</param>
      <param name="node">Specifies which part of the controller to query for its position.</param>
      <returns>This method returns true when the Vector3 passed in was filled out correctly, and false if otherwise.</returns>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.HoldCanceledEventArgs.source">
      <summary>
        <para>The <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> (hand, controller, or user's voice) that canceled the hold gesture.</para>
        <para>Interactions captured via <see cref="UnityEngine.XR.WSA.Input.InteractionManager"></see>, as well as other gesture events, should have a matching <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> for the same hand, controller, or user's voice.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.HoldCanceledEventArgs.sourcePose">
      <summary>
        <para>Represents pose data of the input source, such as a hand or controller, when the gesture occurred.</para>
        <para>Contains a getter for velocity, as well as position, rotation, and ray of both the grip and pointer, of the input source.</para>
      </summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.Input.InteractionSourcePose.TryGetRight(UnityEngine.Vector3@,UnityEngine.XR.WSA.Input.InteractionSourceNode)">
      <summary>Gets the right vector of the interaction source, assuming rotation is valid.</summary>
      <param name="right">The right vector of the interaction source, if the function returns true.</param>
      <param name="node">Specifies which part of the controller to query for its right vector.</param>
      <returns>This method returns true if rotation is valid and the Vector3 passed in was filled out correctly, and false if otherwise.</returns>
    </member>
    <member name="M:UnityEngine.XR.WSA.Input.InteractionSourcePose.TryGetRotation(UnityEngine.Quaternion@,UnityEngine.XR.WSA.Input.InteractionSourceNode)">
      <summary>Gets the rotation of the interaction source, assuming the backing data is valid.</summary>
      <param name="rotation">The rotation of the interaction source, if the function returns true.</param>
      <param name="node">Specifies which part of the controller to query for its rotation.</param>
      <returns>This method returns true if the Quaternion passed in was filled out correctly, and false if otherwise.</returns>
    </member>
    <member name="M:UnityEngine.XR.WSA.Input.InteractionSourcePose.TryGetUp(UnityEngine.Vector3@,UnityEngine.XR.WSA.Input.InteractionSourceNode)">
      <summary>Gets the up vector of the interaction source, assuming rotation is valid.</summary>
      <param name="up">The up vector of the interaction source, if the function returns true.</param>
      <param name="node">Specifies which part of the controller to query for its up vector.</param>
      <returns>Returns true if the rotation is valid and the Vector3 passed in was filled out correctly, and false if otherwise.</returns>
    </member>
    <member name="M:UnityEngine.XR.WSA.Input.InteractionSourcePose.TryGetVelocity(UnityEngine.Vector3@)">
      <summary>Gets the velocity of the interaction source, assuming the backing data is valid.</summary>
      <param name="velocity">The velocity of the interaction source, if the function returns true.</param>
      <returns>Returns true if the Vector3 passed in was filled out correctly, and false if otherwise.</returns>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourcePressedEventArgs.pressType">
      <summary>Denotes the type of button that was just pressed.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourcePressedEventArgs.state">
      <summary>The current state of the reported interaction source that just had one of its buttons enter the pressed state.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceProperties.sourceLossMitigationDirection">
      <summary>The direction you should suggest that the user move their hand if it is nearing the edge of the detection area.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceProperties.sourceLossRisk">
      <summary>Gets the risk that detection of the hand will be lost as a value from 0.0 to 1.0.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSource.id">
      <summary>The identifier for the interaction source (hand, controller, or user's voice).</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSource.kind">
      <summary>Specifies the kind of an interaction source.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSource.productId">
      <summary>
        <para>Following the make and model nomenclature of cars, this equates to the model number.</para>
        <para>In practice, if a new model of a controller came out that looked materially different, you'd see a different product ID, not just a different version number.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSource.productVersion">
      <summary>
        <para>Following the make and model nomenclature of cars, this would be a minor update to the model.</para>
        <para>In practice, if a new model of a controller came out that looked materially different, you'd see a different product ID, not just a different version number.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSource.supportsGrasp">
      <summary>This property returns true when the interaction source has at least one grasp button, and false if otherwise.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSource.supportsMenu">
      <summary>This property returns true when the interaction source has a menu button, and false if otherwise.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSource.supportsPointing">
      <summary>This property returns true if the interaction source has a separate pose for the pointer, and false if otherwise.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSource.supportsThumbstick">
      <summary>Returns true if the interaction source has a thumbstick, and false if otherwise.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSource.supportsTouchpad">
      <summary>Returns true if the interaction source has a touchpad, and false if otherwise.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSource.vendorId">
      <summary>All interaction sources developed by the same company will have the same vendor ID.</summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.Input.GestureRecognizer.CancelGestures">
      <summary>Cancels any pending gesture events. Additionally this will call StopCapturingGestures.</summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.Input.GestureRecognizer.Dispose">
      <summary>
        <para>Disposes the resources used by gesture recognizer.</para>
        <para>Calling this method will make the gesture recognizer stop functioning. You must unsubscribe from gesture-handling events before calling this method.</para>
      </summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.Input.GestureRecognizer.GetRecognizableGestures">
      <summary>Retrieve a mask of the currently enabled gestures.</summary>
      <returns>A mask indicating which Gestures are currently recognizable.</returns>
    </member>
    <member name="M:UnityEngine.XR.WSA.Input.GestureRecognizer.IsCapturingGestures">
      <summary>
        <para>Used to query if the GestureRecognizer is currently receiving Gesture events.</para>
        <para>The GestureRecognizer will receive events after StartCapuringGestures is called and stop when StopCapturingGestures or CancelGestures is called.</para>
      </summary>
      <returns>True if the GestureRecognizer is receiving events or false otherwise.</returns>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceDetectedEventArgs.state">
      <summary>The current state of the reported interaction source that was just detected.</summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.Input.GestureRecognizer.SetRecognizableGestures(UnityEngine.XR.WSA.Input.GestureSettings)">
      <summary>
        <para>Set the recognizable gestures to the ones specified in newMaskValues and return the old settings.</para>
        <para>Note that some combinations of gestures are not compatible. Currently Path cannot be used with either or both of Zoom and Scroll.</para>
      </summary>
      <param name="newMaskValue">A mask indicating which gestures are now recognizable.</param>
      <returns>The previous value.</returns>
    </member>
    <member name="M:UnityEngine.XR.WSA.Input.GestureRecognizer.StartCapturingGestures">
      <summary>
        <para>Call to begin receiving gesture events on this recognizer. No events will be received until this method is called.</para>
        <para>A common use case may be turn to on capturing while an object has focus and turn it off when an object is out of focus.</para>
      </summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.Input.GestureRecognizer.StopCapturingGestures">
      <summary>
        <para>Call to stop receiving gesture events on this recognizer.</para>
        <para>Note that you may still receive pending events after this method is called. Call CancelGestures if you wish to ensure no further events are received.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.GestureErrorEventArgs.error">
      <summary>A readable error string (when possible).</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.GestureErrorEventArgs.hresult">
      <summary>The HRESULT code from the platform.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSourceLostEventArgs.state">
      <summary>The current state of the reported interaction source that was just lost.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.InteractionSource.handedness">
      <summary>Denotes which hand was used as the input source.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.InteractionSourceKind.Other">
      <summary>The interaction source is of a kind not known in this version of the API.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.InteractionSourceKind.Hand">
      <summary>The interaction source is one of the user's hands.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.InteractionSourceKind.Voice">
      <summary>The interaction source is the user's speech.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.InteractionSourceKind.Controller">
      <summary>The interaction source is of a kind not known in this version of the API.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.RecognitionStartedEventArgs.headPose">
      <summary>Head pose of the user at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.RecognitionStartedEventArgs.source">
      <summary>
        <para>The <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> (hand, controller, or user's voice) that started the gesture.</para>
        <para>Interactions captured via <see cref="UnityEngine.XR.WSA.Input.InteractionManager"></see>, as well as other gesture events, should have a matching <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> for the same hand, controller, or user's voice.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.RecognitionStartedEventArgs.sourcePose">
      <summary>Pose data of the interaction source at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.TappedEventArgs.headPose">
      <summary>Head pose of the user at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.TappedEventArgs.source">
      <summary>
        <para>The <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> (hand, controller, or user's voice) that initiated the tap gesture.</para>
        <para>Interactions captured via <see cref="UnityEngine.XR.WSA.Input.InteractionManager"></see>, as well as other gesture events, should have a matching <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> for the same hand, controller, or user's voice.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.TappedEventArgs.sourcePose">
      <summary>Pose data of the interaction source at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.TappedEventArgs.tapCount">
      <summary>The number of taps (1 for single-tap, 2 for double-tap).</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.GestureSettings.None">
      <summary>Disable support for gestures.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.GestureSettings.Tap">
      <summary>
        <para>Enable support for the tap gesture.</para>
        <para>This represents either an air tap with a hand (finger press followed by finger release), saying the word "Select" with your voice. This gesture can be used to activate the hologram or other object that the user is looking at.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.GestureSettings.DoubleTap">
      <summary>
        <para>Enable support for the double-tap gesture.</para>
        <para>This represents two quick air taps with a hand (finger press followed by finger release) or two quick presses and releases of the primary button on a controller. Note: if the both Tap and Double Tap is requested both callbacks will be called on a double tap.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.GestureSettings.Hold">
      <summary>
        <para>Enable support for the hold gesture.</para>
        <para>This represents the user holding down either their finger or the primary button on a controller for longer than the system's hold threshold. This gesture can be used to take a secondary action, such as showing a menu.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.GestureSettings.ManipulationTranslate">
      <summary>
        <para>Enable support for the manipulation gesture which tracks changes to the hand's position. This gesture is relative to the start position of the gesture and measures an absolute movement through the world.</para>
        <para>This represents the user holding down their finger and moving their hand around in the world. This gesture can be used to move, resize or rotate a hologram when you want the hologram to react 1:1 to the user's hand movements. This can also be used to draw new holograms in the world.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.GestureSettings.NavigationX">
      <summary>
        <para>Enable support for the navigation gesture, in the horizontal axis.</para>
        <para>This represents the user holding down their finger and moving their hand or a controller within a normalized cube with coordinates from -1.0 to 1.0. These are normalized values and do not represent any physical unit, such as meters. This gesture can be used to navigate UI widgets, such as radial menus. This can also be used to build velocity-based continuous scrolling or zooming gestures, similar to scrolling a 2D UI by clicking the middle mouse button and then moving the mouse up and down.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.GestureSettings.NavigationY">
      <summary>
        <para>Enable support for the navigation gesture, in the vertical axis.</para>
        <para>This represents the user holding down their finger and moving their hand or a controller within a normalized cube with coordinates from -1.0 to 1.0. These are normalized values and do not represent any physical unit, such as meters. This gesture can be used to navigate UI widgets, such as radial menus. This can also be used to build velocity-based continuous scrolling or zooming gestures, similar to scrolling a 2D UI by clicking the middle mouse button and then moving the mouse up and down.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.GestureSettings.NavigationZ">
      <summary>
        <para>Enable support for the navigation gesture, in the depth axis.</para>
        <para>This represents the user holding down their finger and moving their hand or a controller within a normalized cube with coordinates from -1.0 to 1.0. These are normalized values and do not represent any physical unit, such as meters. This gesture can be used to navigate UI widgets, such as radial menus. This can also be used to build velocity-based continuous scrolling or zooming gestures, similar to scrolling a 2D UI by clicking the middle mouse button and then moving the mouse up and down.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.GestureSettings.NavigationRailsX">
      <summary>
        <para>Enable support for the navigation gesture, in the horizontal axis using rails (guides).</para>
        <para>This represents the user holding down their finger and moving their hand or a controller within a normalized cube with coordinates from -1.0 to 1.0. These are normalized values and do not represent any physical unit, such as meters. This gesture can be used to build velocity-based scrolling or zooming that locks to an axis if the user initiates the gesture primarily in that direction.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.GestureSettings.NavigationRailsY">
      <summary>
        <para>Enable support for the navigation gesture, in the vertical axis using rails (guides).</para>
        <para>This represents the user holding down their finger and moving their hand or a controller within a normalized cube with coordinates from -1.0 to 1.0. These are normalized values and do not represent any physical unit, such as meters. This gesture can be used to build velocity-based scrolling or zooming that locks to an axis if the user initiates the gesture primarily in that direction.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.GestureSettings.NavigationRailsZ">
      <summary>
        <para>Enable support for the navigation gesture, in the depth axis using rails (guides).</para>
        <para>This represents the user holding down their finger and moving their hand or a controller within a normalized cube with coordinates from -1.0 to 1.0. These are normalized values and do not represent any physical unit, such as meters. This gesture can be used to build velocity-based scrolling or zooming that locks to an axis if the user initiates the gesture primarily in that direction.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.NavigationCanceledEventArgs.headPose">
      <summary>Head pose of the user at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.NavigationCanceledEventArgs.source">
      <summary>
        <para>The <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> (hand, controller, or user's voice) that canceled the navigation gesture.</para>
        <para>Interactions captured via <see cref="UnityEngine.XR.WSA.Input.InteractionManager"></see>, as well as other gesture events, should have a matching <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> for the same hand, controller, or user's voice.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.NavigationCanceledEventArgs.sourcePose">
      <summary>Pose data of the interaction source at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.NavigationCompletedEventArgs.headPose">
      <summary>Head pose of the user at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.NavigationCompletedEventArgs.normalizedOffset">
      <summary>The normalized offset, since the navigation gesture began, of the input within the unit cube for the navigation gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.NavigationCompletedEventArgs.source">
      <summary>
        <para>The <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> (hand, controller, or user's voice) that completed the navigation gesture.</para>
        <para>Interactions captured via <see cref="UnityEngine.XR.WSA.Input.InteractionManager"></see>, as well as other gesture events, should have a matching <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> for the same hand, controller, or user's voice.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.NavigationCompletedEventArgs.sourcePose">
      <summary>Pose data of the interaction source at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.NavigationStartedEventArgs.headPose">
      <summary>Head pose of the user at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.NavigationStartedEventArgs.source">
      <summary>
        <para>The <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> (hand, controller, or user's voice) that started the navigation gesture.</para>
        <para>Interactions captured via <see cref="UnityEngine.XR.WSA.Input.InteractionManager"></see>, as well as other gesture events, should have a matching <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> for the same hand, controller, or user's voice.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.NavigationStartedEventArgs.sourcePose">
      <summary>Pose data of the interaction source at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.NavigationUpdatedEventArgs.headPose">
      <summary>Head pose of the user at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.NavigationUpdatedEventArgs.normalizedOffset">
      <summary>The normalized offset, since the navigation gesture began, of the input within the unit cube for the navigation gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.NavigationUpdatedEventArgs.source">
      <summary>
        <para>The <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> (hand, controller, or user's voice) being used for the navigation gesture.</para>
        <para>Interactions captured via <see cref="UnityEngine.XR.WSA.Input.InteractionManager"></see>, as well as other gesture events, should have a matching <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> for the same hand, controller, or user's voice.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.NavigationUpdatedEventArgs.sourcePose">
      <summary>Pose data of the interaction source at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.RecognitionEndedEventArgs.headPose">
      <summary>Head pose of the user at the time of the gesture.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.RecognitionEndedEventArgs.source">
      <summary>
        <para>The <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> (hand, controller, or user's voice) that ended the gesture.</para>
        <para>Interactions captured via <see cref="UnityEngine.XR.WSA.Input.InteractionManager"></see>, as well as other gesture events, should have a matching <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see> for the same hand, controller, or user's voice.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.Input.RecognitionEndedEventArgs.sourcePose">
      <summary>Pose data of the interaction source at the time of the gesture.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.InteractionSourceNode.Grip">
      <summary>
        <para>The grip of the controller.</para>
        <para>The grip and the pointer of a controller are usually angled differently. The grip is the main part of the controller that the player grips with their hand. The main use case for this part of the controller is holding an object in the user's hand, such sa a sword or gun. If you wanted to pick something in the scene from a controller pose, this is most likely the ray you would want to ray-cast with, assuming you're rendering something other than the controller model.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.InteractionSourceNode.Pointer">
      <summary>
        <para>The pointer of the controller.</para>
        <para>The grip and the pointer of a controller are usually angled differently. The pointer, is the part of the controller furthest away from the player, and doesn't generally directly grip with their hand. If you wanted to pick something in the scene from a controller pose, and you render the controller programmatically, this may be the ray you would want to ray-cast with.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.InteractionSourcePositionAccuracy.None">
      <summary>A position accuracy of None reports that there is no position accuracy, as the interaction source unlocatable.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.InteractionSourcePositionAccuracy.Approximate">
      <summary>
        <para>A position accuracy of Approximate reports that you may not want to fully trust the positions reported, as the position is inferred or synthesized in some way, such as the controller leaving the sensors' field of view and forcing the API to rely on the device's IMU instead of visual tracking.</para>
        <para>Approximate is never reported for hands (see <see cref="UnityEngine.XR.WSA.Input.InteractionSourceKind"></see> and <see cref="UnityEngine.XR.WSA.Input.InteractionSourceHandedness"></see> on <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see>), as their positions are only ever reported during visual tracking. If you are making an experience that requires high position accuracy, such as a painting app, you may want to rely on positions reported with High accuracy and discard anything reported as Approximate. For simpler operatons, such as pointing at UI with the interaction source, Approxmiate is generally reliable enough.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.InteractionSourcePositionAccuracy.High">
      <summary>
        <para>A position accuracy of High reports that you can fully trust the position, as the interaction source is within the sensors' visual field of view.</para>
        <para>High is always reported for hands (see <see cref="UnityEngine.XR.WSA.Input.InteractionSourceKind"></see> and <see cref="UnityEngine.XR.WSA.Input.InteractionSourceHandedness"></see> on <see cref="UnityEngine.XR.WSA.Input.InteractionSource"></see>), as their positions are only ever reported during visual tracking. If you are making an experience that requires high position accuracy, such as a painting app, you may want to rely on positions reported with High accuracy and discard anything reported as Approximate. For simpler operatons, such as pointing at UI with the interaction source, Approxmiate is generally reliable enough.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.InteractionSourcePressType.Select">
      <summary>Depending on the InteractionSourceType of the interaction source, this could be a number of equivalent things: main button on a blicker, air-tap on a hand, and the trigger on a motion controller.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.InteractionSourcePressType.Menu">
      <summary>This button is marked with three horizontal lines, same as you would fine on an Xbox One controller.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.InteractionSourcePressType.Grasp">
      <summary>These buttons are generally found on the side of the controller. Some hardware has more than one grasp button.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.InteractionSourcePressType.Touchpad">
      <summary>A touchpad only counts as pressed when it's held down enough - otherwise, it's just touched, and will give a reading of the position through <see cref="UnityEngine.XR.WSA.Input.InteractionSourceState.touchpadPosition"></see>.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Input.InteractionSourcePressType.Thumbstick">
      <summary>Similar to the touchpad, moving the thumbstick won't count as pressing it - a press will occur when pressing down on the thumbstick enough.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.PhotoCapture.CaptureResultType.Success">
      <summary>Specifies that the desired operation was successful.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.PhotoCapture.CaptureResultType.UnknownError">
      <summary>
        <para>Specifies that an unknown error occurred.</para>
        <para>To determine the exact error that occurred, you can search for the hResult on MSDN.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.PhotoCapture.PhotoCaptureResult.hResult">
      <summary>
        <para>The specific HResult value.</para>
        <para>When working with the HoloLens, the hResult will contain the specific error code.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.PhotoCapture.PhotoCaptureResult.resultType">
      <summary>A generic result that indicates whether or not the PhotoCapture operation succeeded.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.WebCam.PhotoCapture.PhotoCaptureResult.success">
      <summary>Indicates whether or not the operation was successful.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.WebCam.CameraParameters.cameraResolutionHeight">
      <summary>
        <para>A valid height resolution for use with the web camera.</para>
        <para>This value must be set to a valid height resolution supported by the intended capture mode. For example, when using this with PhotoCapture, you will want to query <see cref="UnityEngine.XR.WSA.WebCam.PhotoCapture.SupportedResolutions"></see> for a valid height.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.WebCam.CameraParameters.cameraResolutionWidth">
      <summary>
        <para>A valid width resolution for use with the web camera.</para>
        <para>This value must be set to a valid width resolution supported by the intended capture mode. For example, when using this with PhotoCapture, you will want to query <see cref="UnityEngine.XR.WSA.WebCam.PhotoCapture.SupportedResolutions"></see> for a valid width.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.WebCam.CameraParameters.frameRate">
      <summary>
        <para>The framerate at which to capture video. This is only for use with VideoCapture.</para>
        <para>To get a list of supported frame rates based on your desired resolution, call <see cref="UnityEngine.XR.WSA.WebCam.VideoCapture.SupportedResolutions"></see>.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.WebCam.CameraParameters.hologramOpacity">
      <summary>
        <para>The opacity of captured holograms.</para>
        <para>This value must be within the range of 0.0 to 1.0. You must have also indicated that you wanted to capture holograms when you created your capture object.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.WebCam.CameraParameters.pixelFormat">
      <summary>The pixel format used to capture and record your image data.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.WebCam.PhotoCapture.SupportedResolutions">
      <summary>
        <para>A list of all the supported device resolutions for taking pictures.</para>
        <para>Prints out a list of all the supported device resolutions that can be used when taking pictures.</para>
      </summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.WebCam.PhotoCapture.Dispose">
      <summary>
        <para>Dispose must be called to shutdown the PhotoCapture instance.</para>
        <para>If your PhotoCapture instance successfully called <see cref="UnityEngine.XR.WSA.WebCam.PhotoCapture.StartPhotoModeAsync"></see>, you must make sure that you call <see cref="UnityEngine.XR.WSA.WebCam.PhotoCapture.StopPhotoModeAsync"></see> before disposing your PhotoCapture instance.</para>
      </summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.WebCam.PhotoCapture.GetUnsafePointerToVideoDeviceController">
      <summary>
        <para>Provides a COM pointer to the native IVideoDeviceController.</para>
        <para>This method provides direct access to the native COM IVideoDeviceController object. Please use caution when calling this method. The IVideoDeviceController object allows you to control the device settings on the camera. Please note that a reference will be added to the IVideoDeviceController COM pointer each time this method is invoked. The caller is responsible for releasing each instance of the COM pointer.</para>
      </summary>
      <returns>A native COM pointer to the IVideoDeviceController.</returns>
    </member>
    <member name="P:UnityEngine.XR.WSA.Persistence.WorldAnchorStore.anchorCount">
      <summary>(Read Only) Gets the number of persisted world anchors in this WorldAnchorStore.</summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.Persistence.WorldAnchorStore.Clear">
      <summary>Clears all persisted WorldAnchors.</summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.Persistence.WorldAnchorStore.Delete(System.String)">
      <summary>Deletes a persisted WorldAnchor from the store.</summary>
      <param name="id">The identifier of the WorldAnchor to delete.</param>
      <returns>Whether or not the WorldAnchor was found and deleted.</returns>
    </member>
    <member name="M:UnityEngine.XR.WSA.Persistence.WorldAnchorStore.GetAllIds">
      <summary>Gets all of the identifiers of the currently persisted WorldAnchors.</summary>
      <returns>An array of string identifiers.</returns>
      <seealso cref="M:UnityEngine.XR.WSA.Persistence.WorldAnchorStore.Save(System.String,UnityEngine.XR.WSA.WorldAnchor)">
      </seealso>
    </member>
    <member name="M:UnityEngine.XR.WSA.Persistence.WorldAnchorStore.GetAllIds(System.String[])">
      <summary>
        <para>Gets all of the identifiers of the currently persisted WorldAnchors.</para>
        <para>If the target array is not large enough to contain all the identifiers, then only those identifiers that fit within the array will be stored and the return value will equal the size of the array. You can detect this condition by checking for a return value less than <see cref="UnityEngine.XR.WSA.Persistence.WorldAnchorStore.anchorCount"></see>.</para>
      </summary>
      <param name="ids">A target array to receive the identifiers of the currently persisted world anchors.</param>
      <returns>The number of identifiers stored in the target array.</returns>
      <seealso cref="M:UnityEngine.XR.WSA.Persistence.WorldAnchorStore.Save(System.String,UnityEngine.XR.WSA.WorldAnchor)">
      </seealso>
    </member>
    <member name="M:UnityEngine.XR.WSA.Persistence.WorldAnchorStore.Load(System.String,UnityEngine.GameObject)">
      <summary>Loads a WorldAnchor from disk for given identifier and attaches it to the GameObject. If the GameObject has a WorldAnchor, that WorldAnchor will be updated. If the anchor is not found, null will be returned and the GameObject and any existing WorldAnchor attached to it will not be modified.</summary>
      <param name="id">The identifier of the WorldAnchor to load.</param>
      <param name="go">The object to attach the WorldAnchor to if found.</param>
      <returns>The WorldAnchor loaded by the identifier or null if not found.</returns>
    </member>
    <member name="M:UnityEngine.XR.WSA.Persistence.WorldAnchorStore.Save(System.String,UnityEngine.XR.WSA.WorldAnchor)">
      <summary>Saves the provided WorldAnchor with the provided identifier. If the identifier is already in use, the method will return false.</summary>
      <param name="id">The identifier to save the anchor with. This needs to be unique for your app.</param>
      <param name="anchor">The anchor to save.</param>
      <returns>Whether or not the save was successful. Will return false if the id conflicts with another already saved anchor's id.</returns>
    </member>
    <member name="P:UnityEngine.XR.WSA.Sharing.WorldAnchorTransferBatch.anchorCount">
      <summary>(Read Only) Gets the number of world anchors in this WorldAnchorTransferBatch.</summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.Sharing.WorldAnchorTransferBatch.AddWorldAnchor(System.String,UnityEngine.XR.WSA.WorldAnchor)">
      <summary>Adds a WorldAnchor to the batch with the specified identifier.</summary>
      <param name="id">The identifier associated with this anchor in the batch. This must be unique per batch.</param>
      <param name="anchor">The anchor to add to the batch.</param>
      <returns>Whether or not the anchor was added successfully.</returns>
      <seealso cref="P:UnityEngine.XR.WSA.Sharing.WorldAnchorTransferBatch.anchorCount">
      </seealso>
    </member>
    <member name="M:UnityEngine.XR.WSA.Sharing.WorldAnchorTransferBatch.Dispose">
      <summary>Cleans up the WorldAnchorTransferBatch and releases memory.</summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.Sharing.WorldAnchorTransferBatch.GetAllIds">
      <summary>Gets all of the identifiers currently mapped in this WorldAnchorTransferBatch.</summary>
      <returns>The identifiers of all of the WorldAnchors in this WorldAnchorTransferBatch.</returns>
    </member>
    <member name="M:UnityEngine.XR.WSA.Sharing.WorldAnchorTransferBatch.GetAllIds(System.String[])">
      <summary>Gets all of the identifiers currently mapped in this WorldAnchorTransferBatch. If the target array is not large enough to contain all the identifiers, then only those identifiers that fit within the array will be stored and the return value will equal the size of the array. You can detect this condition by checking for a return value less than <see cref="UnityEngine.XR.WSA.Sharing.WorldAnchorTransferBatch.anchorCount"></see>.</summary>
      <param name="ids">A target array to receive the identifiers of the currently mapped world anchors.</param>
      <returns>The number of identifiers stored in the target array.</returns>
    </member>
    <member name="M:UnityEngine.XR.WSA.Sharing.WorldAnchorTransferBatch.LockObject(System.String,UnityEngine.GameObject)">
      <summary>Locks the provided GameObject to the world by loading and applying the WorldAnchor from the TransferBatch for the provided id.</summary>
      <param name="id">The identifier for the WorldAnchor to load and apply to the GameObject.</param>
      <param name="go">The GameObject to apply the WorldAnchor to. If the GameObject already has a WorldAnchor, it will be updated.</param>
      <returns>The loaded WorldAnchor or null if the id does not map to a WorldAnchor.</returns>
    </member>
    <member name="F:UnityEngine.XR.WSA.Sharing.SerializationCompletionReason.Succeeded">
      <summary>The operation has completed successfully.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Sharing.SerializationCompletionReason.NotSupported">
      <summary>The operation has failed because it was not supported.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Sharing.SerializationCompletionReason.AccessDenied">
      <summary>The operation has failed because access was denied. This occurs typically because the transfer batch was not readable when deserializing or writable when serializing.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.Sharing.SerializationCompletionReason.UnknownError">
      <summary>The operation has failed in an unexpected way.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.WebCam.PhotoCaptureFrame.dataLength">
      <summary>The length of the raw IMFMediaBuffer which contains the image captured.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.WebCam.PhotoCaptureFrame.hasLocationData">
      <summary>Specifies whether or not spatial data was captured.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.WebCam.PhotoCaptureFrame.pixelFormat">
      <summary>The raw image data pixel format.</summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.WebCam.PhotoCaptureFrame.Dispose">
      <summary>Disposes the PhotoCaptureFrame and any resources it uses.</summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.WebCam.PhotoCaptureFrame.GetUnsafePointerToBuffer">
      <summary>
        <para>Provides a COM pointer to the native IMFMediaBuffer that contains the image data.</para>
        <para>This method provides very low level access to the native COM IMFMediaBuffer object. Therefore care and caution should be applied when using this method. Please note that each time this method is invoked, an added reference will be applied to the IMFMediaBuffer COM pointer. The caller is responsible for releasing each instance of the COM pointer.</para>
      </summary>
      <returns>A native COM pointer to the IMFMediaBuffer which contains the image data.</returns>
    </member>
    <member name="M:UnityEngine.XR.WSA.WebCam.PhotoCaptureFrame.TryGetCameraToWorldMatrix(UnityEngine.Matrix4x4@)">
      <summary>
        <para>This method will return the camera to world matrix at the time the photo was captured if location data if available.</para>
        <para>If location data is unavailable then the camera to world matrix will be set to the identity matrix.</para>
      </summary>
      <param name="cameraToWorldMatrix">A matrix to be populated by the Camera to world Matrix.</param>
      <returns>True if a valid matrix is returned or false otherwise. This will be false if the frame has no location data.</returns>
    </member>
    <member name="M:UnityEngine.XR.WSA.WebCam.PhotoCaptureFrame.TryGetProjectionMatrix(System.Single,System.Single,UnityEngine.Matrix4x4@)">
      <summary>
        <para>This method will return the projection matrix at the time the photo was captured if location data if available.</para>
        <para>If the near and far clip values are not specified, then the projection matrix returned will be the raw HoloLens projection matrix. However if the near and far clip values are provided, they will be encoded into the returned projection matrix. The provided near and far clip values will be validated prior to encoding them into the projection matrix. The near clip value will be set to 0.01 if the provided value is less than 0.01. Likewise, if the far clip value is less than the near clip value then the far clip value will be set to the near clip value plus 0.01. If location data is unavailable then the projection matrix will be set to the identity matrix.</para>
      </summary>
      <param name="nearClipPlane">The near clip plane distance.</param>
      <param name="farClipPlane">The far clip plane distance.</param>
      <param name="projectionMatrix">A matrix to be populated by the Projection Matrix.</param>
      <returns>True if a valid matrix is returned or false otherwise. This will be false if the frame has no location data.</returns>
    </member>
    <member name="M:UnityEngine.XR.WSA.WebCam.PhotoCaptureFrame.TryGetProjectionMatrix(UnityEngine.Matrix4x4@)">
      <summary>
        <para>This method will return the projection matrix at the time the photo was captured if location data if available.</para>
        <para>If the near and far clip values are not specified, then the projection matrix returned will be the raw HoloLens projection matrix. However if the near and far clip values are provided, they will be encoded into the returned projection matrix. The provided near and far clip values will be validated prior to encoding them into the projection matrix. The near clip value will be set to 0.01 if the provided value is less than 0.01. Likewise, if the far clip value is less than the near clip value then the far clip value will be set to the near clip value plus 0.01. If location data is unavailable then the projection matrix will be set to the identity matrix.</para>
      </summary>
      <param name="projectionMatrix">A matrix to be populated by the Projection Matrix.</param>
      <returns>True if a valid matrix is returned or false otherwise. This will be false if the frame has no location data.</returns>
    </member>
    <member name="M:UnityEngine.XR.WSA.WebCam.PhotoCaptureFrame.UploadImageDataToTexture(UnityEngine.Texture2D)">
      <summary>
        <para>This method will copy the captured image data into a user supplied texture for use in Unity.</para>
        <para>You may only use this method if you specified the BGRA32 format in your <see cref="UnityEngine.XR.WSA.WebCam.CameraParameters"></see>. Keep in mind that this operation will happen on the main thread and therefore be slow. The captured image will also appear flipped on the HoloLens. You can reorient the image by using a custom shader.</para>
      </summary>
      <param name="targetTexture">The target texture that the captured image data will be copied to.</param>
    </member>
    <member name="P:UnityEngine.XR.WSA.HolographicSettings.IsDisplayOpaque">
      <summary>This method returns whether or not the display associated with the main camera reports as opaque.</summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.HolographicSettings.SetFocusPointForFrame(UnityEngine.Vector3)">
      <summary>
        <para>Sets a point in 3d space that is the focal point of the scene for the user for this frame. This helps improve the visual fidelity of content around this point. This must be set every frame.</para>
        <para>The point may be moving through space, the normal indicates the direction that the point is moving. The HoloLens will attempt to compensate for movement in the display around the focal plane / focal point in the scene. You can help the system along by providing information about how the focal point is moving. As an example, if your focus point is following a character as he jumps around your living room, the HoloLens is attempting to compensate only for the motion of your head as it is moving relative to the focal point. The HoloLens will not be factoring in the motion of the character the user is most likely focusing on at this point in time. By providing a normal and a velocity to help inform on how the character is moving within the scene the HoloLens can better compensate and bring greater visual fidelity to the character as he moves around your scene. Specifying the content in focus is body locked will improve the fidelity of body locked content at the expense of content not locked to the body. This is especially apparent as the user translates. You can visualize the focus point / plane in the web interface for the HoloLens.</para>
      </summary>
      <param name="position">The position of the focal point in the scene, relative to the camera.</param>
    </member>
    <member name="M:UnityEngine.XR.WSA.HolographicSettings.SetFocusPointForFrame(UnityEngine.Vector3,UnityEngine.Vector3)">
      <summary>
        <para>Sets a point in 3d space that is the focal point of the scene for the user for this frame. This helps improve the visual fidelity of content around this point. This must be set every frame.</para>
        <para>The point may be moving through space, the normal indicates the direction that the point is moving. The HoloLens will attempt to compensate for movement in the display around the focal plane / focal point in the scene. You can help the system along by providing information about how the focal point is moving. As an example, if your focus point is following a character as he jumps around your living room, the HoloLens is attempting to compensate only for the motion of your head as it is moving relative to the focal point. The HoloLens will not be factoring in the motion of the character the user is most likely focusing on at this point in time. By providing a normal and a velocity to help inform on how the character is moving within the scene the HoloLens can better compensate and bring greater visual fidelity to the character as he moves around your scene. Specifying the content in focus is body locked will improve the fidelity of body locked content at the expense of content not locked to the body. This is especially apparent as the user translates. You can visualize the focus point / plane in the web interface for the HoloLens.</para>
      </summary>
      <param name="position">The position of the focal point in the scene, relative to the camera.</param>
      <param name="normal">Surface normal of the plane being viewed at the focal point.</param>
    </member>
    <member name="M:UnityEngine.XR.WSA.HolographicSettings.SetFocusPointForFrame(UnityEngine.Vector3,UnityEngine.Vector3,UnityEngine.Vector3)">
      <summary>
        <para>Sets a point in 3d space that is the focal point of the scene for the user for this frame. This helps improve the visual fidelity of content around this point. This must be set every frame.</para>
        <para>The point may be moving through space, the normal indicates the direction that the point is moving. The HoloLens will attempt to compensate for movement in the display around the focal plane / focal point in the scene. You can help the system along by providing information about how the focal point is moving. As an example, if your focus point is following a character as he jumps around your living room, the HoloLens is attempting to compensate only for the motion of your head as it is moving relative to the focal point. The HoloLens will not be factoring in the motion of the character the user is most likely focusing on at this point in time. By providing a normal and a velocity to help inform on how the character is moving within the scene the HoloLens can better compensate and bring greater visual fidelity to the character as he moves around your scene. Specifying the content in focus is body locked will improve the fidelity of body locked content at the expense of content not locked to the body. This is especially apparent as the user translates. You can visualize the focus point / plane in the web interface for the HoloLens.</para>
      </summary>
      <param name="position">The position of the focal point in the scene, relative to the camera.</param>
      <param name="normal">Surface normal of the plane being viewed at the focal point.</param>
      <param name="velocity">A vector that describes how the focus point is moving in the scene at this point in time. This allows the HoloLens to compensate for both your head movement and the movement of the object in the scene.</param>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.PhotoCaptureFileOutputFormat.PNG">
      <summary>
        <para>PNG Encoding.</para>
        <para>Using this option will cause the captured image to be saved to disk using the PNG format.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.PhotoCaptureFileOutputFormat.JPG">
      <summary>
        <para>JPEG Encoding.</para>
        <para>Using this option will cause the captured image to be saved to disk using the JPEG format.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.WebCamMode.None">
      <summary>Resource is not in use.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.WebCamMode.PhotoMode">
      <summary>
        <para>Resource is in Photo Mode.</para>
        <para>This mode is entered when calling <see cref="UnityEngine.XR.WSA.WebCam.PhotoCapture.StartPhotoModeAsync"></see> and this mode is exited when calling <see cref="UnityEngine.XR.WSA.WebCam.PhotoCapture.StopPhotoModeAsync"></see>.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.WebCamMode.VideoMode">
      <summary>
        <para>Resource is in Video Mode.</para>
        <para>This mode is entered when calling <see cref="UnityEngine.XR.WSA.WebCam.VideoCapture.StartVideoModeAsync"></see> and this mode is exited when calling <see cref="UnityEngine.XR.WSA.WebCam.VideoCapture.StopVideoModeAsync"></see>.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.CapturePixelFormat.BGRA32">
      <summary>8 bits per channel (blue, green, red, and alpha).</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.CapturePixelFormat.NV12">
      <summary>8-bit Y plane followed by an interleaved U/V plane with 2x2 subsampling.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.CapturePixelFormat.JPEG">
      <summary>Encode photo in JPEG format.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.CapturePixelFormat.PNG">
      <summary>Portable Network Graphics Format.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.VideoCapture.VideoCaptureResult.resultType">
      <summary>A generic result that indicates whether or not the VideoCapture operation succeeded.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.WebCam.VideoCapture.VideoCaptureResult.success">
      <summary>Indicates whether or not the operation was successful.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.VideoCapture.AudioState.MicAudio">
      <summary>Only include the mic audio in the video recording.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.VideoCapture.AudioState.ApplicationAudio">
      <summary>Only include the application audio in the video recording.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.VideoCapture.AudioState.ApplicationAndMicAudio">
      <summary>Include both the application audio as well as the mic audio in the video recording.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.VideoCapture.AudioState.None">
      <summary>Do not include any audio in the video recording.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.VideoCapture.CaptureResultType.Success">
      <summary>Specifies that the desired operation was successful.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.VideoCapture.CaptureResultType.UnknownError">
      <summary>
        <para>Specifies that an unknown error occurred.</para>
        <para>To determine the exact error that occurred, you can search for the hResult on MSDN.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.WebCam.WebCam.Mode">
      <summary>
        <para>Specifies what mode the Web Camera is currently in.</para>
        <para>Only a single instance of PhotoCapture or VideoCapture can be active at any given time. You can query the mode property if you want to know what mode the web camera is currently in.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.WebCam.VideoCapture.SupportedResolutions">
      <summary>A list of all the supported device resolutions for recording videos.</summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.WebCam.VideoCapture.IsRecording">
      <summary>Indicates whether or not the VideoCapture instance is currently recording video.</summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.WebCam.VideoCapture.Dispose">
      <summary>
        <para>Dispose must be called to shutdown the PhotoCapture instance.</para>
        <para>If your VideoCapture instance successfully called <see cref="UnityEngine.XR.WSA.WebCam.VideoCapture.StartVideoModeAsync"></see>, you must make sure that you call <see cref="UnityEngine.XR.WSA.WebCam.VideoCapture.StopVideoModeAsync"></see> before disposing your VideoCapture instance.</para>
      </summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.WebCam.VideoCapture.GetUnsafePointerToVideoDeviceController">
      <summary>
        <para>Provides a COM pointer to the native IVideoDeviceController.</para>
        <para>This method provides direct access to the native COM IVideoDeviceController object. Please use caution when calling this method. The IVideoDeviceController object allows you to control the device settings on the camera. Please note that a reference will be added to the IVideoDeviceController COM pointer each time this method is invoked. The caller is responsible for releasing each instance of the COM pointer.</para>
      </summary>
      <returns>A native COM pointer to the IVideoDeviceController.</returns>
    </member>
    <member name="M:UnityEngine.XR.WSA.WebCam.VideoCapture.GetSupportedFrameRatesForResolution(UnityEngine.Resolution)">
      <summary>
        <para>Returns the supported frame rates at which a video can be recorded given a resolution.</para>
        <para>Use <see cref="UnityEngine.XR.WSA.WebCam.VideoCapture.SupportedResolutions"></see> to get the supported web camera recording resolutions.</para>
      </summary>
      <param name="resolution">A recording resolution.</param>
      <returns>The frame rates at which the video can be recorded.</returns>
    </member>
    <member name="F:UnityEngine.XR.WSA.WebCam.VideoCapture.VideoCaptureResult.hResult">
      <summary>
        <para>The specific HResult value.</para>
        <para>When working with the HoloLens, the hResult will contain the specific error code.</para>
      </summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.SurfaceObserver.Dispose">
      <summary>Call Dispose when the SurfaceObserver is no longer needed. This will ensure that the object is cleaned up appropriately but will not affect any Meshes, components, or objects returned by RequestMeshAsync.</summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.SurfaceObserver.SetVolumeAsAxisAlignedBox(UnityEngine.Vector3,UnityEngine.Vector3)">
      <summary>
        <para>This method sets the observation volume as an axis aligned box at the requested location. Successive calls can be used to reshape the observation volume and/or to move it in the scene as needed. Extents are the distance from the center of the box to its edges along each axis.</para>
        <para>Very large observation volumes will increase overhead of calling <see cref="UnityEngine.XR.WSA.SurfaceObserver.Update"></see> as the number of observable Surfaces grows.</para>
      </summary>
      <param name="origin">The origin of the requested observation volume.</param>
      <param name="extents">The extents in meters of the requested observation volume.</param>
    </member>
    <member name="M:UnityEngine.XR.WSA.SurfaceObserver.SetVolumeAsFrustum(UnityEngine.Plane[])">
      <summary>This method sets the observation volume as a frustum at the requested location. Successive calls can be used to reshape the observation volume and/or to move it in the scene as needed.</summary>
      <param name="planes">Planes defining the frustum as returned from GeometryUtility.CalculateFrustumPlanes.</param>
    </member>
    <member name="M:UnityEngine.XR.WSA.SurfaceObserver.SetVolumeAsOrientedBox(UnityEngine.Vector3,UnityEngine.Vector3,UnityEngine.Quaternion)">
      <summary>
        <para>This method sets the observation volume as an oriented box at the requested location. Successive calls can be used to reshape the observation volume and/or to move it in the scene as needed. Extents are the distance from the center of the box to its edges along each axis.</para>
        <para>Very large observation volumes will increase overhead of calling <see cref="UnityEngine.XR.WSA.SurfaceObserver.Update"></see> as the number of observable Surfaces grows.</para>
      </summary>
      <param name="origin">The origin of the requested observation volume.</param>
      <param name="extents">The extents in meters of the requested observation volume.</param>
      <param name="orientation">The orientation of the requested observation volume.</param>
    </member>
    <member name="M:UnityEngine.XR.WSA.SurfaceObserver.SetVolumeAsSphere(UnityEngine.Vector3,System.Single)">
      <summary>
        <para>This method sets the observation volume as a sphere at the requested location. Successive calls can be used to reshape the observation volume and/or to move it in the scene as needed.</para>
        <para>Very large observation volumes will increase overhead of calling <see cref="UnityEngine.XR.WSA.SurfaceObserver.Update"></see> as the number of observable Surfaces grows.</para>
      </summary>
      <param name="origin">The origin of the requested observation volume.</param>
      <param name="radiusMeters">The radius in meters of the requested observation volume.</param>
    </member>
    <member name="P:UnityEngine.XR.InputTracking.disablePositionalTracking">
      <summary>
        <para>Disables positional tracking in XR. This takes effect the next time the head pose is sampled. If set to true the camera only tracks headset rotation state.</para>
        <para>This will disable the neck model in seated XR experiences. The only positional component remaining is the space between the eyes. This functionality is most useful for 360 video use case where you don't want to allow the head to translate at all.</para>
      </summary>
    </member>
    <member name="M:UnityEngine.XR.InputTracking.GetLocalPosition(UnityEngine.XR.XRNode)">
      <summary>
        <para>Gets the position of a specific node.</para>
        <para>This can be used to keep objects at the same position as the given node. For example if the user picked up an object you could use this method along with <see cref="UnityEngine.XR.InputTracking.GetLocalRotation"></see> to ensure the object is correctly positioned and oriented to match the user's hand.</para>
      </summary>
      <param name="node">Specifies which node's position should be returned.</param>
      <returns>The position of the node in its local tracking space.</returns>
    </member>
    <member name="M:UnityEngine.XR.InputTracking.GetLocalRotation(UnityEngine.XR.XRNode)">
      <summary>
        <para>Gets the rotation of a specific node.</para>
        <para>This can be used to keep objects at the same orientation as the given node. For example if the user picked up an object you could use this method along with <see cref="UnityEngine.XR.InputTracking.GetLocalPosition"></see> to ensure the object is correctly positioned and oriented to match the user's hand.</para>
      </summary>
      <param name="node">Specifies which node's rotation should be returned.</param>
      <returns>The rotation of the node in its local tracking space.</returns>
    </member>
    <member name="M:UnityEngine.XR.InputTracking.Recenter">
      <summary>
        <para>Center tracking to the current position and orientation of the HMD.</para>
        <para>This only works with seated and standing experiences. Room scale experiences are not effected by Recenter.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.WSA.WorldAnchor.isLocated">
      <summary>Returns true if this WorldAnchor is located (read only). A return of false typically indicates a loss of tracking.</summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.WorldAnchor.GetNativeSpatialAnchorPtr">
      <summary>Retrieve a native pointer to the <see href="windows.perception.spatial.spatialanchor" cref="Windows.Perception.Spatial.SpatialAnchor"></see> COM object. This function calls <see href="ms691379" cref="IUnknown::AddRef"></see> on the pointer before returning it. The pointer must be released by calling <see href="ms682317" cref="IUnknown::Release"></see>.</summary>
      <returns>The native pointer to the <see href="windows.perception.spatial.spatialanchor" cref="Windows.Perception.Spatial.SpatialAnchor"></see> COM object.</returns>
    </member>
    <member name="M:UnityEngine.XR.WSA.WorldAnchor.SetNativeSpatialAnchorPtr(System.IntPtr)">
      <summary>Assigns the <c>Windows.Perception.Spatial.SpatialAnchor</c> COM pointer maintained by this <see cref="UnityEngine.XR.WSA.WorldAnchor"></see>.</summary>
      <param name="spatialAnchorPtr">A live <see href="windows.perception.spatial.spatialanchor" cref="Windows.Perception.Spatial.SpatialAnchor"></see> COM pointer.</param>
    </member>
    <member name="P:UnityEngine.XR.XRDevice.fovZoomFactor">
      <summary>
        <para>Zooms the XR projection.</para>
        <para>Set this to zoom the XR projection matrix by scaling the viewing frustum. The value is clamped so that it will never fall below 1.0f. For asymmetric XR projections, setting the FoV doesn't make sense, so use this property to scale the frustum half angles uniformly by a single value. For example: A symmetric frustum starting with an FoV of 90 degrees, an fovZoomFactor of 2 will scale the viewing frustum so that it has an FoV of 45 degrees.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.XRDevice.isPresent">
      <summary>Successfully detected a XR device in working order.</summary>
    </member>
    <member name="P:UnityEngine.XR.XRDevice.model">
      <summary>Specific model of loaded XR device.</summary>
    </member>
    <member name="P:UnityEngine.XR.XRDevice.refreshRate">
      <summary>
        <para>Refresh rate of the display in Hertz.</para>
        <para>This property may return zero if the current XR SDK does not report refresh rate information.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.XRDevice.userPresence">
      <summary>
        <para>Indicates whether the user is present and interacting with the device.</para>
        <para>Many XR devices such as HMDs can detect whether the user is currently wearing and/or interacting with the device. This property can be used to test the state of this user interaction. The exact behavior of this property will vary with each type of device -- some devices will have a sensor specifically to detect user proximity, and users will rely on movement, but applications can reasonably infer that a user is present with the device when the property is <see cref="UnityEngine.XR.UserPresenceState.Present"></see>.</para>
      </summary>
    </member>
    <member name="M:UnityEngine.XR.XRDevice.GetNativePtr">
      <summary>
        <para>This method returns an IntPtr representing the native pointer to the XR device if one is available, otherwise the value will be IntPtr.Zero.</para>
        <para>This native pointer can be used along with other plugins or extensions to access additional details or functionality related to the XR device.</para>
      </summary>
      <returns>The native pointer to the XR device.</returns>
    </member>
    <member name="M:UnityEngine.XR.XRDevice.GetTrackingSpaceType">
      <summary>Returns the device's current TrackingSpaceType. This value determines how the camera is positioned relative to its starting position. For more, see the section "Understanding the camera" in VROverview.</summary>
      <returns>The device's current TrackingSpaceType.</returns>
    </member>
    <member name="M:UnityEngine.XR.XRDevice.SetTrackingSpaceType(UnityEngine.XR.TrackingSpaceType)">
      <summary>Sets the device's current TrackingSpaceType. Returns true on success. Returns false if the given TrackingSpaceType is not supported or the device fails to switch.</summary>
      <returns>True on success. False if the given TrackingSpaceType is not supported or the device fails to switch.</returns>
    </member>
    <member name="F:UnityEngine.XR.WSA.SurfaceData.bakeCollider">
      <summary>Set this field to true when requesting data to bake collider data. This field will be set to true when receiving baked data if it was requested. Setting this field to true requires that a valid outputCollider is also specified.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.SurfaceData.id">
      <summary>This is the ID for the surface to be baked or the surface that was baked and being returned to the user.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.SurfaceData.outputAnchor">
      <summary>
        <para>This WorldAnchor is used to lock the surface into place relative to real world objects. It will be filled in when calling RequestMeshAsync to generate data for a surface and returned with the SurfaceDataReadyDelegate.</para>
        <para>This anchor allows the device to lock the corresponding surface in place relative to real world objects as its knowledge of the real world changes. All generated mesh data will be local to this coordinate system. The outputAnchor parameter is required when calling RequestMeshAsync since spatial mapping meshes are intended to map the real world.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.SurfaceData.outputCollider">
      <summary>This MeshCollider will receive the baked physics mesh prepared by the system when requesting baked surface data through RequestMeshAsync. The MeshCollider is returned in the SurfaceDataReadyDelegate for those users requiring advanced workflows.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.SurfaceData.outputMesh">
      <summary>This MeshFilter will receive the baked mesh prepared by the system when requesting baked surface data. The MeshFilter is returned in the SurfaceDataReadyDelegate for those users requiring advanced workflows.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.SurfaceData.trianglesPerCubicMeter">
      <summary>
        <para>This value controls the basic resolution of baked mesh data and is returned with the SurfaceDataReadyDelegate. The device will deliver up to this number of triangles per cubic meter.</para>
        <para>Computation time for RequestMeshAsync calls and memory overhead for generated data scale with the requested triangle density. Values greater than 1000 will map very closely to the real world but will be very heavy with large bake time latencies. Values less than 100 will be very light and relatively quick to bake but will smooth over many important features in the real world. Values greater than 500 are a good blend of overhead and fidelity but use whatever values make sense for your application. Note that the system will do its best to deliver mesh data at the requested resolution but may round the value down to reduce cost.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.SurfaceId.handle">
      <summary>The actual integer ID referring to a single surface.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.PositionalLocatorState.Unavailable">
      <summary>
        <para>The device's spatial location system is not available.</para>
        <para>By default the Unity will only render the tracking loss image when the device is in this state.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.PositionalLocatorState.OrientationOnly">
      <summary>The device is reporting its orientation and has not been asked to report its position in the user's surroundings.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.PositionalLocatorState.Activating">
      <summary>
        <para>The device is reporting its orientation and is preparing to locate its position in the user's surroundings.</para>
        <para>By default the Unity will only render the tracking loss image when the device is in this state.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.PositionalLocatorState.Active">
      <summary>
        <para>The device is reporting its orientation and position in the user's surroundings.</para>
        <para>This is the normal operational mode for the device.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.PositionalLocatorState.Inhibited">
      <summary>
        <para>The device is reporting its orientation but cannot locate its position in the user's surroundings due to external factors like poor lighting conditions.</para>
        <para>By default Unity will only render the tracking loss image when the device is in this state.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.SurfaceChange.Added">
      <summary>Surface was Added.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.SurfaceChange.Updated">
      <summary>Surface was updated.</summary>
    </member>
    <member name="F:UnityEngine.XR.WSA.SurfaceChange.Removed">
      <summary>Surface was removed.</summary>
    </member>
    <member name="F:UnityEngine.XR.UserPresenceState.Unsupported">
      <summary>The device does not support detecting user presence.</summary>
    </member>
    <member name="F:UnityEngine.XR.UserPresenceState.NotPresent">
      <summary>The device does not detect that the user is present.</summary>
    </member>
    <member name="F:UnityEngine.XR.UserPresenceState.Present">
      <summary>The device detects that the user is present.</summary>
    </member>
    <member name="F:UnityEngine.XR.UserPresenceState.Unknown">
      <summary>The device is currently in a state where it cannot determine user presence.</summary>
    </member>
    <member name="F:UnityEngine.XR.XRNode.LeftEye">
      <summary>Node representing the left eye.</summary>
    </member>
    <member name="F:UnityEngine.XR.XRNode.RightEye">
      <summary>Node representing the right eye.</summary>
    </member>
    <member name="F:UnityEngine.XR.XRNode.CenterEye">
      <summary>Node representing a point between the left and right eyes.</summary>
    </member>
    <member name="F:UnityEngine.XR.XRNode.Head">
      <summary>Node representing the user's head.</summary>
    </member>
    <member name="F:UnityEngine.XR.XRNode.LeftHand">
      <summary>
        <para>Node representing the left hand.</para>
        <para>XR SDKs are responsible for defining which tracked devices represents hands and as such the hands may not always be matched to the user's actual hands, for example if the user passed controllers between their hands after the SDK made the node assignments.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.XRNode.RightHand">
      <summary>
        <para>Node representing the right hand.</para>
        <para>XR SDKs are responsible for defining which tracked devices represents hands and as such the hands may not always be matched to the user's actual hands, for example if the user passed controllers between their hands after the SDK made the node assignments.</para>
      </summary>
    </member>
    <member name="F:UnityEngine.XR.XRNode.GameController">
      <summary>Represents a tracked game Controller not associated with a specific hand.</summary>
    </member>
    <member name="F:UnityEngine.XR.XRNode.TrackingReference">
      <summary>Represents a stationary physical device that can be used as a point of reference in the tracked area.</summary>
    </member>
    <member name="F:UnityEngine.XR.XRNode.HardwareTracker">
      <summary>Represents a physical device that provides tracking data for objects to which it is attached.</summary>
    </member>
    <member name="M:UnityEngine.XR.XRStats.TryGetDroppedFrameCount(System.Int32@)">
      <summary>
        <para>Retrieves the number of dropped frames reported by the XR SDK.</para>
        <para>The number of dropped frames can be useful to games or applications that wish to dynamically scale content or settings in order to maximize frame rate. It is important for XR applications to run at a consistent, high frame rate. If an application is drawing too much or making too many calculations, it may be unable to maintain a high frame rate and "drop" frames. When the SDK reports that frames are being dropped, the game or application can adjust settings, disable objects, or perform other actions to reduce overhead. Statistics are not always available and can vary based on hardware, SDK, and even frame to frame. As such it is important to check the return value of this method before using the statistic value from the out parameter.</para>
      </summary>
      <param name="droppedFrameCount">Outputs the number of frames dropped since the last update.</param>
      <returns>True if the dropped frame count is available, false otherwise.</returns>
    </member>
    <member name="M:UnityEngine.XR.XRStats.TryGetFramePresentCount(System.Int32@)">
      <summary>
        <para>Retrieves the number of times the current frame has been drawn to the device as reported by the XR SDK.</para>
        <para>If performance degrades, some SDKs may choose to draw the current frame multiple times with or without some kind of adaptation to compensate. The frame present count can tell if the SDK has presented the same frame to the viewer multiple times. Statistics are not always available and can vary based on hardware, SDK, and even frame to frame. As such it is important to check the return value of this method before using the statistic value from the out parameter.</para>
      </summary>
      <param name="framePresentCount">Outputs the number of times the current frame has been presented.</param>
      <returns>True if the frame present count is available, false otherwise.</returns>
    </member>
    <member name="M:UnityEngine.XR.XRStats.TryGetGPUTimeLastFrame(System.Single@)">
      <summary>
        <para>Retrieves the time spent by the GPU last frame, in seconds, as reported by the XR SDK.</para>
        <para>On SDKs that support it, this method allows access to more accurate timing information from the SDK itself. This information can take into account GPU time spent in SDK-specific layers. Statistics are not always available and can vary based on hardware, SDK, and even frame to frame. As such it is important to check the return value of this method before using the statistic value from the out parameter.</para>
      </summary>
      <param name="gpuTimeLastFrame">Outputs the time spent by the GPU last frame.</param>
      <returns>True if the GPU time spent last frame is available, false otherwise.</returns>
    </member>
    <member name="P:UnityEngine.XR.WSA.WorldManager.state">
      <summary>The current state of the world tracking systems.</summary>
    </member>
    <member name="M:UnityEngine.XR.WSA.WorldManager.GetNativeISpatialCoordinateSystemPtr">
      <summary>
        <para>Return the native pointer to Windows::Perception::Spatial::ISpatialCoordinateSystem which was retrieved from an Windows::Perception::Spatial::ISpatialStationaryFrameOfReference object underlying the Unity World Origin.</para>
        <para>The caller is responsible for releasing the reference after being done with it. This function may return null if there is no ISpatialCoordinateSystem available.</para>
      </summary>
      <returns>Pointer to Windows::Perception::Spatial::ISpatialCoordinateSystem.</returns>
    </member>
    <member name="F:UnityEngine.XR.TrackingSpaceType.Stationary">
      <summary>Represents a small space where movement may be constrained or positional tracking is unavailable.</summary>
    </member>
    <member name="F:UnityEngine.XR.TrackingSpaceType.RoomScale">
      <summary>Represents a space large enough for free movement.</summary>
    </member>
    <member name="P:UnityEngine.XR.XRSettings.enabled">
      <summary>
        <para>Globally enables or disables XR for the application.</para>
        <para>Set this to true to enable XR mode for the application. Note that this does not activate XR mode. XR mode is activated when a supported Head Mounted Display (HMD) is connected. The GearVR cannot be disabled once activated. A warning message is shown when attempting to disable a GearVR device.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.XRSettings.eyeTextureDesc">
      <summary>
        <para>Fetch the eye texture RenderTextureDescriptor from the active stereo device.</para>
        <para>If XR is enabled, this returns a RenderTexureDescriptor configured by the stereo device. This greatly simplifies the process of generating temporary render textures for stereo rendering.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.XRSettings.eyeTextureHeight">
      <summary>
        <para>The current height of an eye texture for the loaded device.</para>
        <para>This value will be the product of the default eye texture size for the HMD and <see cref="UnityEngine.XR.XRSettings.eyeTextureResolutionScale"></see>. If XR isn't enabled this value will be zero.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.XRSettings.eyeTextureResolutionScale">
      <summary>
        <para>Controls the actual size of eye textures as a multiplier of the device's default resolution.</para>
        <para>A value of 1.0 will use the default eye texture resolution specified by the XR device. Values less than 1.0 will use lower resolution eye textures, which can possibly improve performance at the expense of a less sharp image. Values greater than 1.0 will use higher resolution eye textures, which can potentially result in a sharper image at the cost of performance and memory. This will always reallocate eye textures, which can be an expensive operation. For dynamically changing eye render resolution on the fly, consider using <see cref="UnityEngine.XR.XRSettings.renderViewportScale"></see> instead.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.XRSettings.eyeTextureWidth">
      <summary>
        <para>The current width of an eye texture for the loaded device.</para>
        <para>This value will be the product of the default eye texture size for the HMD and <see cref="UnityEngine.XR.XRSettings.eyeTextureResolutionScale"></see>. If XR isn't enabled this value will be zero.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.XRSettings.isDeviceActive">
      <summary>
        <para>Read-only value that can be used to determine if the XR device is active.</para>
        <para>When true, Unity is accepting input from the HMD and rendering to the HMD's display(s). This can become false if a device is disconnected, a device could not be intialized (see <see cref="UnityEngine.XR.XRSettings.LoadDeviceByName"></see>), or <see cref="UnityEngine.XR.XRSettings.enabled"></see> is set to false. XR output is automatically mirrored to the main display (if applicable). This can be controlled with <see cref="UnityEngine.XR.XRSettings.showDeviceView"></see>. The main window is still controlled by <see cref="UnityEngine.Screen"></see> and related APIs.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.XRSettings.loadedDeviceName">
      <summary>
        <para>Type of XR device that is currently loaded.</para>
        <para>Note: Rendering to the device may not be happening even though it is loaded. See <see cref="UnityEngine.XR.XRSettings.enabled"></see>. In order to change the currently loaded device or reload the current device, use <see cref="UnityEngine.XR.XRSettings.LoadDeviceByName"></see>.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.XRSettings.occlusionMaskScale">
      <summary>
        <para>A scale applied to the standard occulsion mask for each platform.</para>
        <para>Occlusion masks are used to increase performance by not rendering to pixels that cannot be seen through the XR headset. Some post-processing effects require data from pixels that cannot be seen through the XR headset's restricted field of vision (blur effects, for example) in order to avoid visual artifacts and other display errors. This property scales up the occlusion mask to ensure pixels outside of the XR headset's field of vision are rendered to, allowing post-processing effects to access the required texture data. Scaling up the occlusion mask will incur a performance penalty on the GPU due to the extra pixels being rendered.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.XRSettings.renderViewportScale">
      <summary>
        <para>Controls how much of the allocated eye texture should be used for rendering.</para>
        <para>Valid range is 0.0 to 1.0. This value can be changed at runtime without reallocating eye textures. Therefore it is useful for dynamically adjusting eye render resolution. This value cannot be changed while cameras are being rendered. Attempts to change the value during rendering will be ignored and an error will be logged. Changes made during gameplay updates won't be applied until the next frame. Some XR platforms may not immediately use this value. For this reason, we also provide the read-only property <see href="XR.XRSettings-actualRenderViewportScale" cref="actualRenderViewportScale"></see>, which returns the value that will be used for the current frame. This value does not support deferred rendering. Attempts to change the value in the presence of a camera using deferred rendering will be ignored and an error will be logged.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.XRSettings.showDeviceView">
      <summary>
        <para>Mirror what is shown on the device to the main display, if possible.</para>
        <para>Only the left eye is mirrored. If this is false, it is possible to control what is rendered to the main display by setting the camera's Target Eye field in the editor to target the main display.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.XRSettings.supportedDevices">
      <summary>
        <para>Returns a list of supported XR devices that were included at build time.</para>
        <para>Any of these devices can be loaded with <see cref="UnityEngine.XR.XRSettings.LoadDeviceByName"></see>. In order to get a device to show up in this list, it must be included at build time in <see cref="UnityEditor.PlayerSettings"></see>.</para>
      </summary>
    </member>
    <member name="P:UnityEngine.XR.XRSettings.useOcclusionMesh">
      <summary>
        <para>Specifies whether or not the occlusion mesh should be used when rendering. Enabled by default.</para>
        <para>The occlusion mesh prevents GPU work from happening on portions of the eye texture that won't be visible in the HMD. Disabling this will lead to a decrease in GPU rendering performance. However, this may be needed to deal with certain features such as the grab pass.</para>
      </summary>
    </member>
    <member name="M:UnityEngine.XR.XRSettings.LoadDeviceByName(System.String)">
      <summary>
        <para>Loads the requested device at the beginning of the next frame.</para>
        <para>A list of supported devices which can be passed into this function can be obtained from <see cref="UnityEngine.XR.XRSettings.supportedDevices"></see>. In order to check for success, check <see cref="UnityEngine.XR.XRSettings.loadedDeviceName"></see> on the next frame. This function will try to initialize only the device(s) passed in, it will not fall back to other devices in the <see cref="UnityEngine.XR.XRSettings.supportedDevices"></see> list. You can pass a list of values to fall back to other devices on failure. If no device could be initialized, it will fall back to <see cref="UnityEngine.XR.XRSettings.loadedDeviceName"></see> as an empty string and set <see cref="UnityEngine.XR.XRSettings.enabled"></see> to false. You can disable XR by loading an empty string deviceName. After loading a device, you may want to enable it with <see cref="UnityEngine.XR.XRSettings.enabled"></see>.</para>
      </summary>
      <param name="deviceName">Name of the device from <see cref="UnityEngine.XR.XRSettings.supportedDevices"></see>.</param>
    </member>
    <member name="M:UnityEngine.XR.XRSettings.LoadDeviceByName(System.String[])">
      <summary>
        <para>Loads the requested device at the beginning of the next frame.</para>
        <para>A list of supported devices which can be passed into this function can be obtained from <see cref="UnityEngine.XR.XRSettings.supportedDevices"></see>. In order to check for success, check <see cref="UnityEngine.XR.XRSettings.loadedDeviceName"></see> on the next frame. This function will try to initialize only the device(s) passed in, it will not fall back to other devices in the <see cref="UnityEngine.XR.XRSettings.supportedDevices"></see> list. You can pass a list of values to fall back to other devices on failure. If no device could be initialized, it will fall back to <see cref="UnityEngine.XR.XRSettings.loadedDeviceName"></see> as an empty string and set <see cref="UnityEngine.XR.XRSettings.enabled"></see> to false. You can disable XR by loading an empty string deviceName. After loading a device, you may want to enable it with <see cref="UnityEngine.XR.XRSettings.enabled"></see>.</para>
      </summary>
      <param name="prioritizedDeviceNameList">Prioritized list of device names from <see cref="UnityEngine.XR.XRSettings.supportedDevices"></see>.</param>
    </member>
  </members>
</doc>